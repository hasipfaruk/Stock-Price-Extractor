{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80495015",
   "metadata": {},
   "source": [
    "## Step 1ï¸âƒ£: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746832a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers torch librosa soundfile accelerate huggingface-hub vllm\n",
    "\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188cf447",
   "metadata": {},
   "source": [
    "## Step 2ï¸âƒ£: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Clone the project\n",
    "!git clone https://github.com/hasipfaruk/Stock-Price-Extractor.git\n",
    "\n",
    "# Navigate to project\n",
    "os.chdir(\"Stock-Price-Extractor\")\n",
    "print(\"âœ… Project cloned!\")\n",
    "print(f\"ğŸ“ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b356f38",
   "metadata": {},
   "source": [
    "## Step 3ï¸âƒ£: HuggingFace Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e66bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Set your token (replace with yours)\n",
    "HF_TOKEN = \"hf_YOUR_TOKEN_HERE\"\n",
    "\n",
    "if HF_TOKEN == \"hf_YOUR_TOKEN_HERE\":\n",
    "    print(\"âš ï¸ IMPORTANT: Replace with your actual HuggingFace token!\")\n",
    "    print(\"ğŸ“– Get token from: https://huggingface.co/settings/tokens\")\n",
    "    print(\"1. Go to the link above\")\n",
    "    print(\"2. Create new token (read access is fine)\")\n",
    "    print(\"3. Copy and paste in the line above\")\n",
    "else:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"âœ… Authenticated with HuggingFace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de346617",
   "metadata": {},
   "source": [
    "## Step 4ï¸âƒ£: Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920219b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GPU STATUS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(f\"âœ… GPU Available: {gpu_available}\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(f\"ğŸ“Š GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"\\nâœ¨ GPU enabled - processing will be FAST!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ GPU not available - will use CPU (slower)\")\n",
    "    print(\"ğŸ’¡ To enable GPU: Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a014e",
   "metadata": {},
   "source": [
    "## Step 5ï¸âƒ£: Upload Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create upload directory\n",
    "os.makedirs('uploaded_audio', exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“ Upload audio files:\")\n",
    "print(\"1. Click 'Choose Files'\")\n",
    "print(\"2. Select multiple audio files (WAV, MP3, FLAC, M4A)\")\n",
    "print(\"3. Wait for upload to complete\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"\\nâœ… {len(uploaded)} files uploaded:\")\n",
    "for filename in uploaded.keys():\n",
    "    file_path = f'uploaded_audio/{filename}'\n",
    "    os.rename(filename, file_path)\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"  ğŸ“„ {filename} ({file_size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e3e14",
   "metadata": {},
   "source": [
    "## Step 6ï¸âƒ£: Upload Extraction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload your prompt file\n",
    "print(\"ğŸ“ Upload extraction prompt file:\")\n",
    "print(\"Click 'Choose Files' and select your prompt.txt file\\n\")\n",
    "\n",
    "prompt_files = files.upload()\n",
    "\n",
    "if prompt_files:\n",
    "    prompt_filename = list(prompt_files.keys())[0]\n",
    "    os.rename(prompt_filename, 'colab_prompt.txt')\n",
    "    print(f\"âœ… Prompt uploaded: {prompt_filename}\")\n",
    "    \n",
    "    # Show first 200 chars\n",
    "    with open('colab_prompt.txt', 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"\\nğŸ“– Prompt preview ({len(content)} chars):\")\n",
    "    print(content[:200] + \"...\\n\" if len(content) > 200 else content)\n",
    "else:\n",
    "    print(\"âš ï¸ No prompt file uploaded. Using default prompt.\")\n",
    "    # Create default prompt\n",
    "    default_prompt = \"\"\"Extract stock price information from the transcript.\n",
    "\n",
    "Return JSON with these fields:\n",
    "- index_name: Stock index name (e.g., \\\"S&P 500\\\")\n",
    "- price: Current price\n",
    "- change: Change in points\n",
    "- change_percent: Percent change\n",
    "\n",
    "Return ONLY valid JSON, no explanation.\"\"\"\n",
    "    \n",
    "    with open('colab_prompt.txt', 'w') as f:\n",
    "        f.write(default_prompt)\n",
    "    print(\"âœ… Default prompt created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8cfd0",
   "metadata": {},
   "source": [
    "## Step 7ï¸âƒ£: Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a209335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "project_path = Path.cwd()\n",
    "sys.path.insert(0, str(project_path))\n",
    "\n",
    "# Import functions\n",
    "from app.models.transcribe import transcribe\n",
    "from app.models.llm_extract import extract_with_long_prompt\n",
    "\n",
    "print(\"âœ… Functions imported successfully!\")\n",
    "print(f\"  ğŸ“ transcribe() - ready\")\n",
    "print(f\"  ğŸ“ extract_with_long_prompt() - ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b2c96c",
   "metadata": {},
   "source": [
    "## Step 8ï¸âƒ£: Batch Processing (with Timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Find all audio files\n",
    "audio_files = sorted(list(Path('uploaded_audio').glob('*')))\n",
    "audio_files = [f for f in audio_files if f.suffix.lower() in ['.wav', '.mp3', '.flac', '.m4a', '.ogg']]\n",
    "\n",
    "print(f\"ğŸ“ Found {len(audio_files)} audio files\\n\")\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    print(\"âŒ No audio files to process\")\n",
    "else:\n",
    "    all_results = {}\n",
    "    batch_start_time = time.time()\n",
    "    \n",
    "    for i, audio_file in enumerate(audio_files, 1):\n",
    "        filename = audio_file.name\n",
    "        file_start_time = time.time()\n",
    "        print(f\"[{i}/{len(audio_files)}] Processing {filename}...\", end=' ', flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Clear memory\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Transcribe\n",
    "            trans_start = time.time()\n",
    "            result = transcribe(str(audio_file))\n",
    "            trans_duration = time.time() - trans_start\n",
    "            \n",
    "            transcript = result.get('result') if isinstance(result, dict) else result\n",
    "            trans_time = result.get('time', trans_duration) if isinstance(result, dict) else trans_duration\n",
    "            \n",
    "            # Extract\n",
    "            extract_start = time.time()\n",
    "            extraction = extract_with_long_prompt(transcript, prompt_file='colab_prompt.txt')\n",
    "            extract_duration = time.time() - extract_start\n",
    "            \n",
    "            file_total = time.time() - file_start_time\n",
    "            \n",
    "            all_results[filename] = {\n",
    "                \"status\": \"success\",\n",
    "                \"data\": extraction,\n",
    "                \"timing\": {\n",
    "                    \"transcription_s\": round(trans_time, 3),\n",
    "                    \"extraction_s\": round(extract_duration, 3),\n",
    "                    \"total_s\": round(file_total, 3)\n",
    "                }\n",
    "            }\n",
    "            print(f\"âœ… ({file_total:.2f}s)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            file_total = time.time() - file_start_time\n",
    "            all_results[filename] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)[:100],\n",
    "                \"timing\": {\n",
    "                    \"total_s\": round(file_total, 3)\n",
    "                }\n",
    "            }\n",
    "            print(f\"âŒ ({file_total:.2f}s)\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('batch_results.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    batch_total_time = time.time() - batch_start_time\n",
    "    print(f\"\\nâœ… All results saved to: batch_results.json\")\n",
    "    \n",
    "    # Summary with timing\n",
    "    success = sum(1 for r in all_results.values() if r[\"status\"] == \"success\")\n",
    "    failed = len(all_results) - success\n",
    "    avg_time = sum(r.get(\"timing\", {}).get(\"total_s\", 0) for r in all_results.values() if r[\"status\"] == \"success\") / max(success, 1)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Summary:\")\n",
    "    print(f\"  âœ… Successful: {success}/{len(all_results)}\")\n",
    "    print(f\"  âŒ Failed: {failed}/{len(all_results)}\")\n",
    "    print(f\"  â±ï¸ Batch Total: {batch_total_time:.2f}s\")\n",
    "    print(f\"  â±ï¸ Average per file: {avg_time:.2f}s\")\n",
    "    \n",
    "    # Show sample results with timing\n",
    "    if success > 0:\n",
    "        print(f\"\\nğŸ“ˆ Sample Results:\")\n",
    "        for filename, result in list(all_results.items())[:3]:\n",
    "            if result[\"status\"] == \"success\":\n",
    "                print(f\"\\n  {filename}:\")\n",
    "                data = result[\"data\"]\n",
    "                timing = result.get(\"timing\", {})\n",
    "                print(f\"    Index: {data.get('index_name')}\")\n",
    "                print(f\"    Price: {data.get('price')}\")\n",
    "                print(f\"    Change: {data.get('change')} ({data.get('change_percent')})\")\n",
    "                print(f\"    ğŸ¤ Transcription: {timing.get('transcription_s', 0):.3f}s\")\n",
    "                print(f\"    ğŸ¤– Extraction: {timing.get('extraction_s', 0):.3f}s\")\n",
    "                print(f\"    â±ï¸ Total: {timing.get('total_s', 0):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5672c5f",
   "metadata": {},
   "source": [
    "## Step 9ï¸âƒ£: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“¥ Download your results:\\n\")\n",
    "\n",
    "# Download batch results if exists\n",
    "if Path('batch_results.json').exists():\n",
    "    print(\"1. Downloading batch_results.json (with timing data)...\")\n",
    "    files.download('batch_results.json')\n",
    "    print(\"   âœ… Downloaded!\")\n",
    "\n",
    "print(\"\\nâœ… All files ready for download!\")\n",
    "print(\"\\nCheck the 'Files' tab (left panel) to download any files.\")\n",
    "print(\"\\nğŸ“Š Results include:\")\n",
    "print(\"  - Index name, price, change, change%\")\n",
    "print(\"  - ğŸ¤ Transcription time (seconds)\")\n",
    "print(\"  - ğŸ¤– Extraction time (seconds)\")\n",
    "print(\"  - â±ï¸ Total time per file (seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1b740",
   "metadata": {},
   "source": [
    "## ğŸ‰ Complete!\n",
    "\n",
    "Your stock price extraction is done! ğŸš€\n",
    "\n",
    "**â±ï¸ What You Got:**\n",
    "1. âœ… Stock prices extracted from audio\n",
    "2. ğŸ¤ Transcription time for each file\n",
    "3. ğŸ¤– LLM extraction time for each file\n",
    "4. â±ï¸ Total processing time per file\n",
    "\n",
    "**Next steps:**\n",
    "1. Download `batch_results.json` from the Files panel\n",
    "2. Analyze timing data to optimize performance\n",
    "3. Import results into your spreadsheet or database\n",
    "\n",
    "**For more info:**\n",
    "- See `README.md` for general documentation\n",
    "- See `TIMING_FEATURES.md` for timing guide\n",
    "- See `USAGE.md` for usage examples"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
