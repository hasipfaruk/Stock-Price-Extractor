torch>=2.0.0
transformers>=4.35.0
librosa>=0.10.0
soundfile>=0.12.0
numpy>=1.24.0
requests>=2.31.0
accelerate>=0.24.0
streamlit>=1.28.0
# vLLM for optimized GPU inference (optional)
vllm>=0.2.0
# Additional dependencies for Llama 2
sentencepiece>=0.1.99
protobuf>=3.20.0

