# Stock Index Price Extractor

A fast, open-source solution for extracting stock index price information from audio recordings (5-10 seconds) with processing time under 3 seconds. Works with any audio source containing stock market information.

## ðŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

### Usage Options

#### 1. **Command Line (CLI)** - Easiest for single files
```bash
# Basic usage
python extract_price.py audio.wav

# JSON output
python extract_price.py audio.wav --json

# Verbose with timing
python extract_price.py audio.wav --verbose

# Save to file
python extract_price.py audio.wav --output result.json
```

#### 2. **Python Library** - Use in your own code
```python
from StockPriceExtractor import extract_price

# Quick one-liner
result = extract_price("audio.wav")
print(result['index'], result['price'])

# Or use the class
from StockPriceExtractor import StockPriceExtractor

extractor = StockPriceExtractor()
result = extractor.extract("audio.wav")
```

#### 3. **REST API Server** - For web services
```bash
# Start server
python run_server.py

# Single file
curl -X POST "http://localhost:8000/extract" -F "file=@audio.wav"

# Multiple files (folder)
curl -X POST "http://localhost:8000/extract/batch" \
  -F "files=@audio1.wav" -F "files=@audio2.wav"

# Upload folder as zip
curl -X POST "http://localhost:8000/extract/folder" \
  -F "zip_file=@audio_folder.zip"

# Upload custom model
curl -X POST "http://localhost:8000/models/upload" \
  -F "model_name=my-model" -F "files=@config.json" -F "files=@model.bin"

# Download model
curl -X GET "http://localhost:8000/models/my-model/download" \
  -o my-model.zip

# List models
curl -X GET "http://localhost:8000/models"
```

## ðŸ“‹ Features

- âœ… **Multiple Usage Modes**: CLI, Library, or REST API
- âœ… **Fast Processing**: Optimized for < 3 second processing
- âœ… **Open-Source**: Uses Whisper (speech-to-text) and regex extraction
- âœ… **Cross-Platform**: Works on Windows, Linux, and macOS
- âœ… **CPU/GPU Support**: Auto-detects and optimizes for your hardware
- âœ… **Local Models**: All models stored in project directory
- âœ… **Model Management**: Upload/download custom models via API
- âœ… **Batch Processing**: Process single file, multiple files, or entire folders
- âœ… **Folder Upload**: Upload zip files containing multiple audio files
- âœ… **Easy Integration**: Use as library, CLI tool, or web service

## ðŸ“ Project Structure

```
bloomberg-audio-price-extractor/
â”œâ”€â”€ extract_price.py          # CLI tool (standalone)
â”œâ”€â”€ StockPriceExtractor.py   # Python library
â”œâ”€â”€ run_server.py            # REST API server
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ transcribe.py   # Whisper transcription
â”‚       â””â”€â”€ extract.py       # Price extraction
â”œâ”€â”€ models/                 # Downloaded models stored here
â”œâ”€â”€ examples/               # Usage examples
â”œâ”€â”€ client/                 # API client examples
â””â”€â”€ benchmarks/             # Performance testing
```

## ðŸŽ¯ Use Cases

### 1. Quick One-Time Extraction
```bash
python extract_price.py recording.wav
```

### 2. Batch Processing (Multiple Files)
```python
# Using API
import requests

files = [
    ("files", ("audio1.wav", open("audio1.wav", "rb"))),
    ("files", ("audio2.wav", open("audio2.wav", "rb")))
]
response = requests.post("http://localhost:8000/extract/batch", files=files)
results = response.json()
```

### 3. Folder Upload (Zip File)
```python
# Upload entire folder as zip
import requests

with open("audio_folder.zip", "rb") as f:
    files = {"zip_file": ("folder.zip", f, "application/zip")}
    response = requests.post("http://localhost:8000/extract/folder", files=files)
    results = response.json()
```

### 4. Custom Model Upload/Download
```python
# Upload your own fine-tuned model
import requests

files = [
    ("files", ("config.json", open("config.json", "rb"))),
    ("files", ("pytorch_model.bin", open("model.bin", "rb")))
]
data = {"model_name": "my-custom-model"}
requests.post("http://localhost:8000/models/upload", files=files, data=data)

# Download model
response = requests.get("http://localhost:8000/models/my-custom-model/download")
with open("downloaded_model.zip", "wb") as f:
    f.write(response.content)
```

### 5. Use Custom Model for Extraction
```python
# Extract using custom uploaded model
import requests

with open("audio.wav", "rb") as f:
    files = {"file": ("audio.wav", f)}
    data = {"model_path": "models/custom/my-custom-model"}
    response = requests.post("http://localhost:8000/extract", files=files, data=data)
```

## âš™ï¸ Configuration

Edit `app/config.py` to customize:

```python
# Model selection
MODEL_TRANSCRIBE = "openai/whisper-tiny"  # Fastest (CPU)
MODEL_TRANSCRIBE = "openai/whisper-base"  # Balanced (GPU)

# Device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

## ðŸ“Š Output Format

### CLI Output
```
==================================================
STOCK PRICE EXTRACTION RESULTS
==================================================

ðŸ“Š Index: S&P 500
ðŸ’° Price: 4500.25

ðŸ“ Transcript:
   The S&P 500 is trading at 4500.25...

â±ï¸  Processing Time: 1.234s
==================================================
```

### JSON Output
```json
{
  "index": "S&P 500",
  "price": "4500.25",
  "transcript": "The S&P 500 is trading at 4500.25...",
  "timing": {
    "transcription_s": 1.234
  }
}
```

## ðŸ”§ Requirements

- Python 3.8+
- 4GB+ RAM (8GB recommended)
- ~500MB disk space for models
- CUDA GPU (optional, for faster processing)

## ðŸ“¦ Installation Details

### Dependencies
- `torch` - PyTorch for model inference
- `transformers` - Hugging Face transformers
- `librosa` - Audio processing
- `fastapi` - Web framework (for API server)
- `uvicorn` - ASGI server

### Model Download
Models are automatically downloaded on first use to `models/cache/`:
- `whisper-tiny`: ~75 MB
- `whisper-base`: ~150 MB

## ðŸŽ“ Examples

### CLI Usage
```bash
python extract_price.py audio.wav --verbose
```

### Python Library
```python
from StockPriceExtractor import extract_price
result = extract_price("audio.wav")
```

### REST API
```bash
python run_server.py
curl -X POST "http://localhost:8000/extract" -F "file=@audio.wav"
```

## ðŸš€ Performance

### Target: < 3 seconds processing time

**CPU (whisper-tiny):**
- Typical: 1-2 seconds
- Maximum: 2-3 seconds

**GPU (whisper-base):**
- Typical: 0.5-1.5 seconds
- Maximum: 1-2 seconds

## ðŸ“š Documentation

All documentation is in this README. Models are stored in `models/cache/` directory.

## ðŸ› ï¸ Development

### Run Tests
```bash
python -m app.tests.test_pipeline
```

### Test Performance
Run the CLI tool with `--verbose` to see processing times:
```bash
python extract_price.py audio.wav --verbose
```

## ðŸ“ License

This project uses open-source models:
- Whisper: MIT License
- Transformers: Apache 2.0

## ðŸ¤ Contributing

Contributions welcome! Feel free to submit issues or pull requests.

## ðŸ“ž Support

For questions or issues, please open an issue on the repository.

---

**Made for everyone** - Use it as a CLI tool, Python library, or web service! ðŸŽ‰

