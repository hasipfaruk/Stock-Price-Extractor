# Stock Index Price Extractor

A powerful, **100% open-source** solution for extracting stock index price information from audio recordings using **Llama 2** LLM and **Whisper Large-v3** ASR. Designed to handle complex audio with multiple information. Works with any audio source containing stock market information.

## ðŸ“‹ Recent Updates (Phase 1)

âœ… **100% LLM-Only Enforcement** - Regex extraction completely removed, LLM mandatory  
âœ… **Testing Infrastructure** - Accuracy and latency validation tools included  
âœ… **Comprehensive Documentation** - Complete guides for deployment and validation  

**See [PHASE4_COMPLETE.md](PHASE4_COMPLETE.md) for Phase 1 details**

## ðŸ”’ Client Requirements Compliance

âœ… **Open-Source Only** - Llama 2 instruction-tuned models (NO OpenAI/Gemini/proprietary models)  
âœ… **GPU Optimized** - vLLM with FP16, prefix caching, <3s end-to-end latency  
âœ… **High-Quality ASR** - Whisper Large-v3 for accurate transcription  
âœ… **100% LLM Extraction** - NO regex fallbacks, purely LLM-based natural language understanding  
âœ… **Robust Validation** - Data normalization & strict output structure  

**[See CLIENT_COMPLIANCE.md](CLIENT_COMPLIANCE.md) for detailed requirement verification**

âš ï¸ **IMPORTANT: NO REGEX EXTRACTION** - This solution uses **100% LLM-only** extraction (Llama 2) to handle complex audio transcripts with detailed information. A custom extraction prompt is **REQUIRED** for all extraction operations.

## ðŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

### Usage Options

#### 1. **Streamlit Web App** - Recommended (Easiest to Use) â­

```bash
# Install streamlit (if not already installed)
pip install streamlit

# Run the app
streamlit run streamlit_app.py
```

**Features:**
- Simple drag-and-drop interface
- Upload audio + prompt file (required)
- Automatic LLM extraction (Llama 2)
- View results instantly
- Download results as JSON

**Note**: Prompt is **REQUIRED** for LLM extraction. The app uses 100% LLM-only mode with no regex fallback.

#### 2. **Command Line (CLI)** - For single files
```bash
# With LLM (prompt REQUIRED - no regex fallback)
python extract_price.py audio.wav --prompt-file prompt.txt

# With prompt text
python extract_price.py audio.wav --prompt-text "Extract stock prices..."

# JSON output
python extract_price.py audio.wav --prompt-file prompt.txt --json

# Verbose with timing
python extract_price.py audio.wav --prompt-file prompt.txt --verbose

# Save to file
python extract_price.py audio.wav --use-llm --prompt-file prompt.txt --output result.json
```

#### 3. **Python Library** - Use in your own code
```python
from app.models.transcribe import transcribe
from app.models.extract import extract_detailed
from app.models.llm_extract import extract_with_long_prompt

# Transcribe audio
result = transcribe("audio.wav")
transcript = result['result']

# Extract using regex
extraction = extract_detailed(transcript)
print(extraction['index_name'], extraction['price'])

# Or use LLM extraction
llm_result = extract_with_long_prompt(transcript, prompt_file="prompt.txt")
print(llm_result['index_name'], llm_result['price'])
```


## ðŸ“‹ Features

- âœ… **100% Open-Source**: Llama 2 + Whisper Large-v3 (NO proprietary models)
- âœ… **GPU-Optimized**: vLLM with FP16, prefix caching, <3s end-to-end latency
- âœ… **LLM Extraction**: Full natural language understanding of price expressions
- âœ… **Robust Validation**: Data normalization with strict output structure
- âœ… **Two Usage Modes**: CLI tool or Python library
- âœ… **Fast Processing**: Optimized for < 3 second processing on GPU
- âœ… **Cross-Platform**: Works on Windows, Linux, and macOS
- âœ… **CPU/GPU Support**: Auto-detects and optimizes for your hardware
- âœ… **Local Models**: All models stored in project directory
- âœ… **Easy Integration**: Use as CLI tool or Python library

## ðŸ“ Project Structure

```
bloomberg-audio-price-extractor/
â”œâ”€â”€ extract_price.py          # CLI tool
â”œâ”€â”€ streamlit_app.py          # Web interface
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ transcribe.py     # Whisper transcription
â”‚       â”œâ”€â”€ extract.py        # Regex extraction
â”‚       â”œâ”€â”€ llm_extract.py    # LLM extraction
â”‚       â”œâ”€â”€ normalize.py      # Data normalization
â”‚       â”œâ”€â”€ post_process.py   # Post-processing
â”‚       â”œâ”€â”€ utils.py          # Utility functions
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ models/                   # Downloaded models stored here
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸŽ¯ Use Cases

### 1. Quick One-Time Extraction
```bash
python extract_price.py recording.wav
```

### 2. With LLM Extraction
```bash
python extract_price.py recording.wav --use-llm --prompt-file prompt.txt
```

### 3. Batch Processing
```python
from app.models.transcribe import transcribe
from app.models.extract import extract_detailed
from pathlib import Path

for audio_file in Path(".").glob("*.wav"):
    result = transcribe(str(audio_file))
    transcript = result['result']
    extraction = extract_detailed(transcript)
    print(f"{audio_file}: {extraction['index_name']} @ {extraction['price']}")
```


## âš™ï¸ Configuration

Edit `app/config.py` to customize:

```python
# Model selection
MODEL_TRANSCRIBE = "openai/whisper-large-v3"  # High accuracy
# Or use: "openai/whisper-medium" for speed

# Device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

## ðŸ“Š Output Format

Example output from CLI:

```
==================================================
STOCK PRICE EXTRACTION RESULTS
==================================================

[INDEX] Index: S&P 500
[PRICE] Price: 4500.25
[CHANGE] Change: +50.10
[CHANGE %] Change %: +1.12%
[SESSION] Session: CLOSING

[QUOTE] S&P 500 trading at 4500.25, up 1.12%
==================================================
```

JSON output:

```json
{
  "index_name": "S&P 500",
  "price": "4500.25",
  "change": "+50.10",
  "change_percent": "+1.12%",
  "session": "CLOSING",
  "standardized_quote": "S&P 500 trading at 4500.25, up 1.12%",
  "transcript": "The S&P 500 is up ...",
  "extraction_method": "regex"
}
```

## ðŸ”§ Requirements

- Python 3.8+
- 4GB+ RAM (8GB recommended)
- ~500MB disk space for models
- CUDA GPU (optional, for faster processing)

## ðŸ“¦ Installation Details

Dependencies:
- `torch` - PyTorch for model inference
- `transformers` - Hugging Face transformers
- `librosa` - Audio processing
- `streamlit` - Web interface
- `vllm` - GPU-optimized inference (optional)

Models are automatically downloaded on first use:
- Whisper Large-v3: ~1.5 GB
- Llama 2 7B: ~14 GB (for LLM extraction)

## ðŸŽ“ Quick Examples

CLI:

```bash
python extract_price.py audio.wav --verbose
python extract_price.py audio.wav --use-llm --prompt-file prompt.txt
```

Web App:

```bash
streamlit run streamlit_app.py
```

Python Library:

```python
from app.models.transcribe import transcribe
from app.models.extract import extract_detailed

result = transcribe("audio.wav")
extraction = extract_detailed(result['result'])
print(extraction['index_name'], extraction['price'])
```

## ðŸš€ Performance

**Target: < 3 seconds end-to-end processing**

CPU (Whisper Medium):
- Typical: 1-2 seconds

GPU (Whisper Large-v3):
- Typical: 0.5-1 second

Use `--verbose` flag to see timing details.

## ðŸ“š Documentation

All essential documentation is in this README. For model details, see `app/config.py`.

## ðŸ› ï¸ Development

Test the pipeline:

```bash
python extract_price.py test_audio.wav --verbose
```

Benchmark performance:

```bash
python extract_price.py audio.wav --verbose
```


## ðŸ“ License

This project uses open-source models:
- Whisper: MIT License
- Transformers: Apache 2.0

## ðŸ¤ Contributing

Contributions welcome! Feel free to submit issues or pull requests.

## ðŸ“ž Support

For questions or issues, please open an issue on the repository.

---

**Made for everyone** - Use it as a CLI tool, Python library, or web service! ðŸŽ‰

